{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pAQDjVcychvD"
   },
   "source": [
    "# LLM setup notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "h5qSqQC4_5pO"
   },
   "outputs": [],
   "source": [
    "# Importing all the necessary libraries\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "import os\n",
    "import json\n",
    "import ollama\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vlCasd2hVlzj"
   },
   "source": [
    "### Code to connect all the files in within the ZIP file into one DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "AZEVbTPd8XTT"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Folder containing the JSON files\n",
    "folder_path = \"jobs\"\n",
    "\n",
    "# List to store data\n",
    "data_list = []\n",
    "\n",
    "# Iterate over each JSON file in the extracted folder\n",
    "for file_name in os.listdir(folder_path):\n",
    "    if file_name.endswith('.json'):  # Check if it's a JSON file\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        try:\n",
    "            # Read the JSON file\n",
    "            with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "\n",
    "                df_temp = pd.DataFrame(data)\n",
    "                data_list.append(df_temp)\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_name}: {e}\")\n",
    "\n",
    "# Combine all DataFrames into one named df\n",
    "df = pd.concat(data_list, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>URL</th>\n",
       "      <th>Area</th>\n",
       "      <th>Published</th>\n",
       "      <th>Description</th>\n",
       "      <th>Job Link</th>\n",
       "      <th>HTML_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IT-tekniker til museets udstillingsteknik og d...</td>\n",
       "      <td>https://www.jobindex.dk/vis-job/h579207</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>I forbindelse med åbningen af flere nye udstil...</td>\n",
       "      <td>https://www.jobindexarkiv.dk/cgi/showarchive.c...</td>\n",
       "      <td>Lignende jobannoncer Job i Region Sjælland kat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Front End Developer</td>\n",
       "      <td>https://www.jobindex.dk/vis-job/r6559770</td>\n",
       "      <td>København</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Relevant details not found in the PaidJob-inne...</td>\n",
       "      <td>https://www.jobindexarkiv.dk/cgi/showarchive.c...</td>\n",
       "      <td>Lignende jobannoncer Job i Storkøbenhavn kateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tysktalende IT-supporter/System konsulent</td>\n",
       "      <td>https://www.jobindex.dk/vis-job/r6559726</td>\n",
       "      <td>Søndersø</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Relevant details not found in the PaidJob-inne...</td>\n",
       "      <td>https://www.jobindexarkiv.dk/cgi/showarchive.c...</td>\n",
       "      <td>Lignende jobannoncer Job i Fyn kategoriseret i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Er du en af de absolut dygtigste Test managers?</td>\n",
       "      <td>https://www.jobindex.dk/vis-job/r6559752</td>\n",
       "      <td>København</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Relevant details not found in the PaidJob-inne...</td>\n",
       "      <td>https://www.jobindexarkiv.dk/cgi/showarchive.c...</td>\n",
       "      <td>Lignende jobannoncer Job i Storkøbenhavn kateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Er du en af de absolut dygtigste tekniske test...</td>\n",
       "      <td>https://www.jobindex.dk/vis-job/r6559751</td>\n",
       "      <td>København</td>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>Relevant details not found in the PaidJob-inne...</td>\n",
       "      <td>https://www.jobindexarkiv.dk/cgi/showarchive.c...</td>\n",
       "      <td>Lignende jobannoncer Job i Storkøbenhavn kateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>IT-servicetekniker til TELE-POST</td>\n",
       "      <td>https://www.jobindex.dk/vis-job/r6611189</td>\n",
       "      <td>Grønland</td>\n",
       "      <td>2016-01-30</td>\n",
       "      <td>Relevant details not found in the PaidJob-inne...</td>\n",
       "      <td>https://www.jobindexarkiv.dk/cgi/showarchive.c...</td>\n",
       "      <td>Lignende jobannoncer Job hos Tusass (3) Jobind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1643</th>\n",
       "      <td>Frontend Developer</td>\n",
       "      <td>https://www.jobindex.dk/vis-job/r6610302</td>\n",
       "      <td>København</td>\n",
       "      <td>2016-01-30</td>\n",
       "      <td>Relevant details not found in the PaidJob-inne...</td>\n",
       "      <td>https://www.jobindexarkiv.dk/cgi/showarchive.c...</td>\n",
       "      <td>Lignende jobannoncer Job i Storkøbenhavn kateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>Dynamics AX Senior Konsulenter</td>\n",
       "      <td>https://www.jobindex.dk/vis-job/r6611334</td>\n",
       "      <td>København S</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Relevant details not found in the PaidJob-inne...</td>\n",
       "      <td>https://www.jobindexarkiv.dk/cgi/showarchive.c...</td>\n",
       "      <td>Lignende jobannoncer Job i Storkøbenhavn kateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1645</th>\n",
       "      <td>Programmør og systemudvikler</td>\n",
       "      <td>https://www.jobindex.dk/vis-job/r6611338</td>\n",
       "      <td>Hedehusene</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Relevant details not found in the PaidJob-inne...</td>\n",
       "      <td>https://www.jobindexarkiv.dk/cgi/showarchive.c...</td>\n",
       "      <td>Lignende jobannoncer Job i Storkøbenhavn kateg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1646</th>\n",
       "      <td>Automation Expert - Batch Operation &amp; Infrastr...</td>\n",
       "      <td>https://www.jobindex.dk/vis-job/r6611425</td>\n",
       "      <td>København</td>\n",
       "      <td>2016-01-31</td>\n",
       "      <td>Relevant details not found in the PaidJob-inne...</td>\n",
       "      <td>https://www.jobindexarkiv.dk/cgi/showarchive.c...</td>\n",
       "      <td>Lignende jobannoncer Job i Storkøbenhavn kateg...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1647 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Title  \\\n",
       "0     IT-tekniker til museets udstillingsteknik og d...   \n",
       "1                            Senior Front End Developer   \n",
       "2             Tysktalende IT-supporter/System konsulent   \n",
       "3       Er du en af de absolut dygtigste Test managers?   \n",
       "4     Er du en af de absolut dygtigste tekniske test...   \n",
       "...                                                 ...   \n",
       "1642                   IT-servicetekniker til TELE-POST   \n",
       "1643                                 Frontend Developer   \n",
       "1644                     Dynamics AX Senior Konsulenter   \n",
       "1645                       Programmør og systemudvikler   \n",
       "1646  Automation Expert - Batch Operation & Infrastr...   \n",
       "\n",
       "                                           URL         Area   Published  \\\n",
       "0      https://www.jobindex.dk/vis-job/h579207      Unknown  2016-01-01   \n",
       "1     https://www.jobindex.dk/vis-job/r6559770    København  2016-01-01   \n",
       "2     https://www.jobindex.dk/vis-job/r6559726     Søndersø  2016-01-01   \n",
       "3     https://www.jobindex.dk/vis-job/r6559752    København  2016-01-01   \n",
       "4     https://www.jobindex.dk/vis-job/r6559751    København  2016-01-01   \n",
       "...                                        ...          ...         ...   \n",
       "1642  https://www.jobindex.dk/vis-job/r6611189     Grønland  2016-01-30   \n",
       "1643  https://www.jobindex.dk/vis-job/r6610302    København  2016-01-30   \n",
       "1644  https://www.jobindex.dk/vis-job/r6611334  København S  2016-01-31   \n",
       "1645  https://www.jobindex.dk/vis-job/r6611338   Hedehusene  2016-01-31   \n",
       "1646  https://www.jobindex.dk/vis-job/r6611425    København  2016-01-31   \n",
       "\n",
       "                                            Description  \\\n",
       "0     I forbindelse med åbningen af flere nye udstil...   \n",
       "1     Relevant details not found in the PaidJob-inne...   \n",
       "2     Relevant details not found in the PaidJob-inne...   \n",
       "3     Relevant details not found in the PaidJob-inne...   \n",
       "4     Relevant details not found in the PaidJob-inne...   \n",
       "...                                                 ...   \n",
       "1642  Relevant details not found in the PaidJob-inne...   \n",
       "1643  Relevant details not found in the PaidJob-inne...   \n",
       "1644  Relevant details not found in the PaidJob-inne...   \n",
       "1645  Relevant details not found in the PaidJob-inne...   \n",
       "1646  Relevant details not found in the PaidJob-inne...   \n",
       "\n",
       "                                               Job Link  \\\n",
       "0     https://www.jobindexarkiv.dk/cgi/showarchive.c...   \n",
       "1     https://www.jobindexarkiv.dk/cgi/showarchive.c...   \n",
       "2     https://www.jobindexarkiv.dk/cgi/showarchive.c...   \n",
       "3     https://www.jobindexarkiv.dk/cgi/showarchive.c...   \n",
       "4     https://www.jobindexarkiv.dk/cgi/showarchive.c...   \n",
       "...                                                 ...   \n",
       "1642  https://www.jobindexarkiv.dk/cgi/showarchive.c...   \n",
       "1643  https://www.jobindexarkiv.dk/cgi/showarchive.c...   \n",
       "1644  https://www.jobindexarkiv.dk/cgi/showarchive.c...   \n",
       "1645  https://www.jobindexarkiv.dk/cgi/showarchive.c...   \n",
       "1646  https://www.jobindexarkiv.dk/cgi/showarchive.c...   \n",
       "\n",
       "                                              HTML_Text  \n",
       "0     Lignende jobannoncer Job i Region Sjælland kat...  \n",
       "1     Lignende jobannoncer Job i Storkøbenhavn kateg...  \n",
       "2     Lignende jobannoncer Job i Fyn kategoriseret i...  \n",
       "3     Lignende jobannoncer Job i Storkøbenhavn kateg...  \n",
       "4     Lignende jobannoncer Job i Storkøbenhavn kateg...  \n",
       "...                                                 ...  \n",
       "1642  Lignende jobannoncer Job hos Tusass (3) Jobind...  \n",
       "1643  Lignende jobannoncer Job i Storkøbenhavn kateg...  \n",
       "1644  Lignende jobannoncer Job i Storkøbenhavn kateg...  \n",
       "1645  Lignende jobannoncer Job i Storkøbenhavn kateg...  \n",
       "1646  Lignende jobannoncer Job i Storkøbenhavn kateg...  \n",
       "\n",
       "[1647 rows x 7 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7p0iHNVGAbnE"
   },
   "source": [
    "## Data Preprocessing Before LLM\n",
    "\n",
    "In this step, we preprocess the data to ensure it is ready for the LLM. We remove rows with missing or insufficient information, as well as those that do not align with the project's objectives, ensuring that only relevant and complete data is passed for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    1647.000000\n",
      "mean      630.154220\n",
      "std       341.703805\n",
      "min        66.000000\n",
      "25%       417.500000\n",
      "50%       670.000000\n",
      "75%       826.500000\n",
      "max      4080.000000\n",
      "Name: word_count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Drop rows where 'HTML_Text' is None\n",
    "df = df.dropna(subset=['HTML_Text'])\n",
    "\n",
    "# Calculate word counts for each row in the 'HTML_Text' column\n",
    "df['word_count'] = df['HTML_Text'].apply(lambda x: len(x.split()))\n",
    "\n",
    "# Generate statistics on the word counts\n",
    "stats = df['word_count'].describe()\n",
    "\n",
    "# Print the statistics\n",
    "print(stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "waeBgr8XUks7"
   },
   "source": [
    "### We remove the HTML texts where the word count is less than 400 as those do not give use enought info to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xj5hc_OlZeQ0",
    "outputId": "02a4f355-8dbf-4c6b-e6fc-d65f5d1f28f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1247, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a threshold for minimum word count\n",
    "min_word_count = 400\n",
    "\n",
    "# Filter the original dataframe in place, only keeping rows meeting the word count requirement\n",
    "df = df[df['HTML_Text'].apply(lambda x: len(x.split()) > min_word_count)].copy()\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-rYR74pdUqc7"
   },
   "source": [
    "### Removing additional letters from city names. For example ''Aalborg C'' would become ''Aalborg''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "nCzPFPiTHfbs"
   },
   "outputs": [],
   "source": [
    "# Function to city area indications\n",
    "def clean_trailing_indicators(area):\n",
    "    if pd.isna(area):\n",
    "        return None\n",
    "    # Remove things like 'o', 'c', 'SØ', 'N', 'K'\n",
    "    area = re.sub(r'\\s+[a-zA-ZÆØÅæøå]+$', '', area.strip())\n",
    "    return area\n",
    "\n",
    "# Apply the cleaning function to the 'Area' column\n",
    "df['Area'] = df['Area'].apply(clean_trailing_indicators)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_MDcV2eRV2Ny"
   },
   "source": [
    "### Some ads have more than one city listed as an option. We only keep the city that was listed as the first option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "zeD5lq1mJGAi"
   },
   "outputs": [],
   "source": [
    "# Simplified function to keep the first city\n",
    "def keep_first_place_simple(area):\n",
    "    if pd.isna(area):\n",
    "        return None\n",
    "    # Split by simpler delimiters\n",
    "    delimiters = [',', '/', ' og', ' eller', ' or', ' and']\n",
    "    for delim in delimiters:\n",
    "        if delim in area:\n",
    "            # Keep only the first part\n",
    "            area = area.split(delim)[0].strip()\n",
    "            break\n",
    "    # Return cleaned area if it is meaningful\n",
    "    return area if len(area) > 2 else None\n",
    "\n",
    "# Apply the simplified cleaning function\n",
    "df['Area'] = df['Area'].apply(keep_first_place_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0n29P_EAUx6y"
   },
   "source": [
    "### Mapping the 3 cities that have different name in English vs Danish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "7yNTLlHXRiP_"
   },
   "outputs": [],
   "source": [
    "# Mapping of Danish to English city names\n",
    "city_name_mapping = {\n",
    "    'København': 'Copenhagen',\n",
    "    'Århus': 'Aarhus',\n",
    "    'Helsingør': 'Elsinore'\n",
    "}\n",
    "\n",
    "# Replace Danish names with their English equivalents\n",
    "df['Area'] = df['Area'].replace(city_name_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-a7IHUUOU6dT"
   },
   "source": [
    "### A list of cities we want to look at. If the area is not one of the ones listed, it is removed. These are the 30 biggest cities in Denmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "gBgfJQUyLoxW"
   },
   "outputs": [],
   "source": [
    "# List of 30 biggest cities in Denmark\n",
    "cities = [\n",
    "    \"Copenhagen\", \"Aarhus\", \"Odense\", \"Aalborg\", \"Esbjerg\", \"Randers\", \"Kolding\", \"Horsens\", \"Vejle\", \"Roskilde\",\n",
    "    \"Herning\", \"Hørsholm\", \"Silkeborg\", \"Næstved\", \"Fredericia\", \"Viborg\", \"Køge\", \"Holstebro\", \"Taastrup\", \"Slagelse\",\n",
    "    \"Hillerød\", \"Sønderborg\", \"Svendborg\", \"Hjørring\", \"Holbæk\", \"Frederikshavn\", \"Nørresundby\", \"Ringsted\", \"Haderslev\",\n",
    "    \"Skive\", \"Ølstykke-Stenløse\", \"Nykøbing Falster\", \"Greve Strand\", \"Kalundborg\", \"Ballerup\", \"Rødovre\", \"Lyngby\",\n",
    "    \"Albertslund\", \"Hvidovre\", \"Glostrup\", \"Ishøj\", \"Birkerød\", \"Farum\", \"Frederikssund\", \"Brøndby Strand\",\n",
    "    \"Skanderborg\", \"Hedensted\", \"Frederiksværk\", \"Lillerød\", \"Solrød Strand\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bAwxWogOPBMM",
    "outputId": "3e9c47ab-e3b1-4df1-d00f-252d6e108ae4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered DataFrame:\n",
      "(692, 8)\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame to only include rows where Area is in the cities list\n",
    "df = df[df['Area'].isin(cities)]\n",
    "\n",
    "# Display the filtered DataFrame\n",
    "print(\"Filtered DataFrame:\")\n",
    "print(df.shape)\n",
    "\n",
    "# This is a sample data. Only for a few months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "0RvY3VtpLW4k",
    "outputId": "809aaf07-98fb-44d7-9e81-4acbdb761f84"
   },
   "outputs": [],
   "source": [
    "# # Install Ollama\n",
    "# !sudo apt-get install -y pciutils\n",
    "# !curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ruGKfIYlMd2Q"
   },
   "outputs": [],
   "source": [
    "# Sets up environment variables and starts the Ollama server\n",
    "import os\n",
    "import threading\n",
    "import subprocess\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "vaeOWSMugwt2"
   },
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "\n",
    "Extract relevant skills from a job listing, separating them into **primary IT-related technical skills** and **secondary (soft/general) skills**.\n",
    "\n",
    "### Primary Skills\n",
    "Focus on IT-specific technical skills such as:\n",
    "- Programming languages, frameworks, tools, platforms, and technologies.\n",
    "- Examples: Python, React, Docker, AWS, SQL, Kubernetes.\n",
    "\n",
    "### Secondary Skills\n",
    "Focus on non-technical competencies, including:\n",
    "- Communication, leadership, problem-solving, teamwork, time management.\n",
    "\n",
    "---\n",
    "\n",
    "### Rules:\n",
    "- Categorize skills into **primary** (IT-related) and **secondary** (soft skills).\n",
    "- Split compound terms into separate skills (e.g., \"Python and Java\" → [\"Python\", \"Java\"]).\n",
    "- Exclude vague, repetitive, or non-actionable terms.\n",
    "- Translate all extracted skills into **English** if the input text is in Danish.\n",
    "- Ensure outputs are clear, specific, and concise.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Output Format:\n",
    "```json\n",
    "{\n",
    "  \"skills\": {\n",
    "    \"primary\": [\"Skill 1\", \"Skill 2\", \"...\"],\n",
    "    \"secondary\": [\"Skill A\", \"Skill B\", \"...\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "---\n",
    "\n",
    "Example:\n",
    "\n",
    "Job: \"Looking for Python, Docker, AWS, and strong communication skills.\"\n",
    "\n",
    "Output:\n",
    "{\n",
    "    \"skills\": {\n",
    "    \"primary\": [\"Python\", \"Docker\", \"AWS\"],\n",
    "    \"secondary\": [\"communication\"]\n",
    "  }\n",
    "}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GCB2JYi6-Zei",
    "outputId": "531cc887-a3e0-45b4-a409-687a0ea3b9e7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Function to extract skills (primary and secondary) from job listings\n",
    "def extract_skills(html_text, row_id):\n",
    "    prompt = f\"\"\"\n",
    "    Extract the relevant skills from the following job listing, categorizing them into **primary (IT-related technical skills)** and **secondary (soft/general skills)**.\n",
    "\n",
    "    ### Skills Categories:\n",
    "    1. **Primary Skills:** IT-related technical skills (e.g., Python, AWS, Kubernetes, Docker, SQL, React, etc.).\n",
    "    2. **Secondary Skills:** Soft skills and traits (e.g., Communication, Teamwork, Problem-Solving, Leadership).\n",
    "\n",
    "    ### Rules:\n",
    "    - Split combined skills into distinct terms (e.g., \"Python and Java\" → [\"Python\", \"Java\"]).\n",
    "    - Focus on actionable, specific, and clearly stated skills.\n",
    "    - Outputs must be in **clear and concise English only**, regardless of the input language.\n",
    "    - If no skills are present, return empty lists for both categories.\n",
    "    - Translate all extracted skills into **English** if the input text is in Danish.\n",
    "\n",
    "\n",
    "    Provide the results in this JSON format:\n",
    "    {{\n",
    "      \"skills\": {{\n",
    "        \"primary\": [\"Skill 1\", \"Skill 2\", \"...\"],\n",
    "        \"secondary\": [\"Skill A\", \"Skill B\", \"...\"]\n",
    "      }}\n",
    "    }}\n",
    "\n",
    "    Job Listing Text:\n",
    "    {html_text}\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'http://130.225.39.216:11434/api/chat'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\n",
    "        'model': 'llama3.1:latest',\n",
    "        'messages': [\n",
    "            {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "            {'role': 'user', 'content': prompt}\n",
    "        ],\n",
    "        'format': 'json',\n",
    "        'options': {\"temperature\": 0.1, \"num_ctx\": 8000}\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()  # Raise exception for response errors\n",
    "        return response.json()['message']['content']\n",
    "    except (json.JSONDecodeError, KeyError, requests.exceptions.RequestException) as e:\n",
    "        print(f\"Error for Row {row_id}: {e}\")\n",
    "        return {\"skills\": {\"primary\": [], \"secondary\": []}}\n",
    "\n",
    "# Example usage\n",
    "# row_id = example_data_row_id\n",
    "# html_text = example_html_text\n",
    "# result = extract_skills(html_text, row_id)\n",
    "# print(result)\n",
    "\n",
    "# Function to refine extracted skills\n",
    "import requests\n",
    "import json\n",
    "\n",
    "def refine_skills(extracted_skills, row_id):\n",
    "    refinement_prompt = f\"\"\"\n",
    "    Refine the following extracted skills, ensuring accuracy and clear categorization:\n",
    "\n",
    "    Extracted Skills:\n",
    "    {json.dumps(extracted_skills, indent=2)}\n",
    "\n",
    "    ### Refined Categories:\n",
    "    1. **Primary Skills:** IT-related technical skills only.\n",
    "    2. **Secondary Skills:** Clearly defined soft skills.\n",
    "\n",
    "    ### Rules:\n",
    "    - Keep skills actionable, specific, and IT-relevant for \"primary.\"\n",
    "    - Use concise and clear English.\n",
    "    - Outputs must be in **clear and concise English.**\n",
    "    - Translate all extracted skills into **English** if the input text is in Danish.\n",
    "\n",
    "    Provide the results in this JSON format:\n",
    "    {{\n",
    "      \"skills\": {{\n",
    "        \"primary\": [\"Skill 1\", \"Skill 2\", \"...\"],\n",
    "        \"secondary\": [\"Skill A\", \"Skill B\", \"...\"]\n",
    "      }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'http://130.225.39.216:11434/api/chat'\n",
    "    headers = {'Content-Type': 'application/json'}\n",
    "    data = {\n",
    "        'model': 'llama3.1:latest',\n",
    "        'messages': [\n",
    "            {'role': 'system', 'content': 'SYSTEM_PROMPT'},  # Ensure SYSTEM_PROMPT is defined\n",
    "            {'role': 'user', 'content': refinement_prompt}\n",
    "        ],\n",
    "        'format': 'json',\n",
    "        'options': {\"temperature\": 0.1, \"num_ctx\": 8000},\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        response.raise_for_status()  # Raise an error for a failed request\n",
    "        return response.json()['message']['content']\n",
    "    except (json.JSONDecodeError, KeyError, requests.exceptions.RequestException) as e:\n",
    "        print(f\"Error refining skills for Row {row_id}: {e}\")\n",
    "        return extracted_skills\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 573
    },
    "id": "WozWc-R2B7Ut",
    "outputId": "b8383f8b-40f5-4d00-cb53-e774da844012"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Initialize the DataFrame with the columns for Primary_Skills and Secondary_Skills\n",
    "df['Primary_Skills'] = None\n",
    "df['Secondary_Skills'] = None\n",
    "\n",
    "# Output file to store the results\n",
    "output_file = 'updated_job_listings_with_skills.csv'\n",
    "log_file = '[STEP5]LLM_for_project_progress_log.log'\n",
    "\n",
    "# Create the CSV file with headers before the loop if it doesn't exist\n",
    "if not os.path.exists(output_file):\n",
    "    df[:0].to_csv(output_file, index=False, encoding='utf-8')  # Write only the headers initially\n",
    "\n",
    "# Check the log file to find the last processed row\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as log:\n",
    "        last_processed = int(log.read().strip())\n",
    "else:\n",
    "    last_processed = -1  # Start from the beginning if no log file exists\n",
    "\n",
    "# Process job listings and add extracted skills to the DataFrame\n",
    "for i, html_text in enumerate(df['HTML_Text']):\n",
    "    # Skip rows that have already been processed\n",
    "    if i <= last_processed:\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Extract and refine skills\n",
    "        extracted = extract_skills(html_text, row_id=i + 1)\n",
    "        refined = refine_skills(extracted, row_id=i + 1)\n",
    "\n",
    "        # Safely retrieve primary and secondary skills\n",
    "        primary_skills = \", \".join(refined.get('skills', {}).get('primary', [])) or \"\"\n",
    "        secondary_skills = \", \".join(refined.get('skills', {}).get('secondary', [])) or \"\"\n",
    "\n",
    "        print(f\"Primary Skills for Row {i + 1}: {primary_skills}\")\n",
    "        print(f\"Secondary Skills for Row {i + 1}: {secondary_skills}\")\n",
    "\n",
    "        # Manually construct the row to save\n",
    "        row_to_save = df.iloc[i].to_dict()  # Get the current row as a dictionary\n",
    "        row_to_save['Primary_Skills'] = primary_skills\n",
    "        row_to_save['Secondary_Skills'] = secondary_skills\n",
    "\n",
    "        # Append the row to the CSV file\n",
    "        pd.DataFrame([row_to_save]).to_csv(output_file, mode='a', index=False, header=False, encoding='utf-8')\n",
    "\n",
    "        print(f\"Row {i + 1} saved to {output_file}.\")\n",
    "\n",
    "        # Update the log file with the last processed row\n",
    "        with open(log_file, 'w') as log:\n",
    "            log.write(str(i))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing Row {i + 1}: {e}\")\n",
    "\n",
    "        # Save the row with empty skills to the CSV\n",
    "        row_to_save = df.iloc[i].to_dict()\n",
    "        row_to_save['Primary_Skills'] = \"\"\n",
    "        row_to_save['Secondary_Skills'] = \"\"\n",
    "        pd.DataFrame([row_to_save]).to_csv(output_file, mode='a', index=False, header=False, encoding='utf-8')\n",
    "\n",
    "        # Update the log file with the last processed row, even if it failed\n",
    "        with open(log_file, 'w') as log:\n",
    "            log.write(str(i))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.11 (SDS24)",
   "language": "python",
   "name": "sds24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
